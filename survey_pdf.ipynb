{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdfplumber\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import re\n",
    "\n",
    "\n",
    "import PyPDF2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print iterations progress\n",
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, \\\n",
    "                      length = 100, fill = '█', printEnd = \"\\r\"):\n",
    "    \"\"\"\n",
    "    code_source :https://stackoverflow.com/questions/3173320/text-progress-bar-in-the-console\n",
    "    Call in a loop to create terminal progress bar\n",
    "    Args:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print('\\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix), end = printEnd)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(file_path):\n",
    "    \n",
    "    '''get files under certain path\n",
    "\n",
    "    Args:\n",
    "        file path,string\n",
    "\n",
    "    Returns:\n",
    "        A dictionary for stroing the file name and it's path\n",
    "\n",
    "    Raise;\n",
    "        ValueError,file path name\n",
    "\n",
    "    '''\n",
    "    file_dir ={}\n",
    "    for dirpath, dirnames, files in os.walk(file_path, topdown=False): ## work down certain dir,has 3 returns\n",
    "        \n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.pdf'):\n",
    "                file_dir[file_name] = os.path.join(dirpath,file_name)\n",
    "            \n",
    "    return file_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = get_file_name('./well_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_survey_path(file_dir):\n",
    "    \n",
    "    '''get file contain 'survey'\n",
    "\n",
    "    Args:\n",
    "        file path,string\n",
    "\n",
    "    Returns:\n",
    "        A dictionary for stroing the file name and it's path\n",
    "\n",
    "    Raise;\n",
    "     \n",
    "    '''\n",
    "    survey_path ={}\n",
    "    pattern = r'.*[Ss]urvey'                                                   #pattern\n",
    "    for file,path in file_dir.items():\n",
    "        find_file = re.search(pattern,file)                                    #find the file with such pattern\n",
    "        if find_file:\n",
    "            file_name = find_file.group(0)                                     #save the name for matching the pattern\n",
    "            survey_path[file_name] = path                                      # save file name to dictionary\n",
    "            \n",
    "    return survey_path\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_path = get_survey_path(file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_survey_content(survey_path):\n",
    "\n",
    "    '''get pdf content from the survey_path\n",
    "    code source:https://cloud.tencent.com/developer/article/1386517\n",
    "\n",
    "    Args:\n",
    "        survey_path, dict\n",
    "\n",
    "    Returns:\n",
    "        tables generator\n",
    "\n",
    "    Raise;\n",
    "        file not found error\n",
    "    '''\n",
    "    file_table = {}\n",
    "    for file,path in survey_path.items():\n",
    "        tables = []                                                      # save each page table to tables container\n",
    "        pdf = pdfplumber.open(path)\n",
    "#         print('preprocess file of',path)                                  # start of preprocess file\n",
    "        for page in pdf.pages:\n",
    "            for pdf_table in page.extract_tables():\n",
    "                table = []                                                # each page saved to one table\n",
    "                cells = []\n",
    "                for row in pdf_table:\n",
    "                    if not any(row):\n",
    "                                                                          # 如果一行全为空，则视为一条记录结束\n",
    "                        if any(cells):\n",
    "                            table.append(cells)\n",
    "                            cells = []\n",
    "                    elif all(row):\n",
    "                                                                           # 如果一行全不为空，则本条为新行，上一条结束\n",
    "                        if any(cells):\n",
    "                            table.append(cells)\n",
    "                            cells = []\n",
    "                        table.append(row)\n",
    "                    else:\n",
    "                        if len(cells) == 0:\n",
    "                            cells = row\n",
    "                        else:\n",
    "                            for i in range(len(row)):\n",
    "                                if row[i] is not None:\n",
    "                                    cells[i] = row[i] if cells[i] is None else cells[i] + row[i]\n",
    "                tables.append(table)                                          #append each page to one file container\n",
    "                \n",
    "                for row in table:\n",
    "                    row = [re.sub('\\s', '}', cell) if cell is not None else None for cell in row]\n",
    "#                 print('---------- dash line ----------') ## end of preprocess the file pages\n",
    "        file_table[path] = tables\n",
    "\n",
    "        yield file_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initial_preprocess(file_table):\n",
    "    '''for each file,record the table with well projection data\n",
    "    \n",
    "    Args:\n",
    "        file_table generator\n",
    "    Returns:\n",
    "    \n",
    "    '''\n",
    "    preprocessed_file ={}\n",
    "    output_csv = 'wells_survey'\n",
    "    \n",
    "    try:\n",
    "        for file,tables in file_table.items() : ##iterate through\n",
    "            file_tables = []\n",
    "            for table in tables:\n",
    "                table_rows = []\n",
    "                if len(table) == 8 or len(table) == 9:                                # criterior of data\n",
    "                    for i,row in enumerate(table):\n",
    "                        row_np = np.array(row)\n",
    "                        row_np_squeeze = row_np.squeeze()\n",
    "    #                     print(row_np_squeeze.shape)\n",
    "                        string_np = np.array2string(row_np_squeeze)\n",
    "                        table_rows.append(string_np)                                    # append rows to table\n",
    "\n",
    "                file_tables.append(table_rows)                                          # append table to tables\n",
    "#                 print('-------end of file-----------')                                      #end of preprocess the file\n",
    "        preprocessed_file[file] = file_tables                                          #correlate file with tables\n",
    "            \n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        \n",
    "    return preprocessed_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_preprocess(survey_return):\n",
    "    '''preprocess survey to data to have clean data format\n",
    "    Args:\n",
    "        survey_return ,dictionary\n",
    "    Returns:\n",
    "        cleaned result, dictionary\n",
    "    Raise:\n",
    "    \n",
    "    '''\n",
    "    file_splited_rows = {}\n",
    "    for key,value in preprocessed_file.items():              # terate the dictionary\n",
    "        value_table =[]                                       # container to save cleaned list\n",
    "        value_np = np.array(value)\n",
    "        value_np_squ = value_np.squeeze()                     # squeeze down the numpy array\n",
    "        for array in value_np_squ:                  \n",
    "            if len(array)> 0:                                 # chose those has element\n",
    "                for i in range(0,len(array)):                 # iterate the array\n",
    "                    row_split = array[i].split('\\\\n')          # get the splitted data\n",
    "                    for row in row_split:                     # iterate throught the splited data\n",
    "                        value_table.append(row)                # append to container\n",
    "\n",
    "        file_splited_rows[key] = value_table                   #save data to dictionary\n",
    "\n",
    "    return file_splited_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cleaned_df(file_splited_rows):\n",
    "    '''get cleaned df for each file\n",
    "    if survey data is existed\n",
    "    \n",
    "    Args:\n",
    "        filename correspond to the data list, dictionary\n",
    "        file_dfs,list container for saving the preprocessed df dictionary\n",
    "        \n",
    "    Returns:\n",
    "        filename correspond to a cleaned dataframe\n",
    "        \n",
    "    '''\n",
    "    file_df ={}\n",
    "    for key,value in file_splited_rows.items():                         # iterate the dictionary\n",
    "        clean_data = []\n",
    "        \n",
    "        if value:                                                        # if list not empty\n",
    "            rows = [] \n",
    "            col_name = value[1].split(' ')\n",
    "            clean_data.append(col_name)                                  #container for saving data rows\n",
    "            for i in range(len(value)):                                  # iteratet the datalist \n",
    "                if re.match(r'.\\d+',value[i]):\n",
    "                    rows.append(i)\n",
    "            for row in rows:                                             # iter data row for saving  those data                 \n",
    "                drilling_data = value[row]                                # have the drilling data\n",
    "                drilling_data = drilling_data.replace(\"'\",\"\").split(\" \")\n",
    "#                 drilling_data\n",
    "                clean_data.append(drilling_data)                          # save cleaned data\n",
    "            cleaned_df = pd.DataFrame.from_records(clean_data)\n",
    "            cleaned_df.drop(0,inplace=True,axis=0)\n",
    "            file_df[key] = cleaned_df                                       # save cleaned df to dicionary\n",
    "#         else:                                                             #ignore the empty list\n",
    "#             file_df[key] = []\n",
    "    \n",
    "    return file_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |█---------------------------------------------------------------------------------------------------| 1.8% \r"
     ]
    }
   ],
   "source": [
    "file_dfs = []\n",
    "    \n",
    "file_folder = './well_logs'                                     # file folder ready to be preprocessed\n",
    "tot_length_app = 1000                                           # pregroess tracker\n",
    "pdf_files = get_file_name(file_folder)                          # get all the pdf files\n",
    "pdf_survey_files = get_survey_path(pdf_files)                   # get all the survey pdf files\n",
    "file_table = get_survey_content(pdf_survey_files)               # get content from the survey pdf files\n",
    "for i,table in enumerate(file_table):                          # iterate the generator\n",
    "    preprocessed_file = initial_preprocess(table)               # fist preprocess to have the demanding data\n",
    "    file_splited_rows =second_preprocess(preprocessed_file)     # have the cleaned data\n",
    "    file_df = get_cleaned_df(file_splited_rows)\n",
    "#     print(f'{i}s ',end=' ')\n",
    "    if file_df:\n",
    "        file_dfs.append(file_df)                                #save resutl to list  \n",
    "    time.sleep(0.5)\n",
    "    printProgressBar (i, tot_length_app, prefix = '', suffix = '', decimals = 1, \\\n",
    "                      length = 100, fill = '█', printEnd = \"\\r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
